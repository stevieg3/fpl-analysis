{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating the benchwarmers from the regular starters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we explore the separation of our model into 2 steps: i) predict benchwarmers and ii) predict points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import \\\n",
    "    Dense, \\\n",
    "    LSTM, \\\n",
    "    BatchNormalization, \\\n",
    "    Dropout, \\\n",
    "    Activation\n",
    "from keras import \\\n",
    "    initializers, \\\n",
    "    optimizers, \\\n",
    "    Sequential\n",
    "import keras\n",
    "from hyperopt import hp, fmin, rand, tpe, Trials\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.utils import \\\n",
    "    _load_all_historical_data, \\\n",
    "    _map_season_string_to_ordered_numeric, \\\n",
    "    _generate_known_features_for_next_gw, \\\n",
    "    custom_train_test_split, \\\n",
    "    split_sequences, \\\n",
    "    _load_model_from_pickle\n",
    "from src.models.constants import \\\n",
    "    COLUMNS_TO_DROP_FOR_TRAINING\n",
    "from src.models.LSTM.make_predictions import LSTMPlayerPredictor\n",
    "from src.visualisation.utils import plot_learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    full_data = _load_all_historical_data()\n",
    "    full_data.sort_values(['name', 'season', 'gw'], inplace=True)\n",
    "\n",
    "    _map_season_string_to_ordered_numeric(full_data)\n",
    "    _generate_known_features_for_next_gw(full_data)\n",
    "\n",
    "    # Remove Brendan Galloway due to unexplained gap in gameweek data\n",
    "    full_data = full_data[full_data['name'] != 'brendan_galloway']\n",
    "    full_data.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "#     logging.info(f\"Loaded historical data of shape {full_data.shape}\")\n",
    "\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-10 19:07:26,619 - Loading raw historical FPL data\n",
      "2020-06-10 19:07:26,856 - Creating season order column\n",
      "2020-06-10 19:07:26,864 - Generating known features for next GW\n"
     ]
    }
   ],
   "source": [
    "all_data = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67797, 68)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assists</th>\n",
       "      <th>bonus</th>\n",
       "      <th>bps</th>\n",
       "      <th>clean_sheets</th>\n",
       "      <th>creativity</th>\n",
       "      <th>goals_conceded</th>\n",
       "      <th>goals_scored</th>\n",
       "      <th>ict_index</th>\n",
       "      <th>influence</th>\n",
       "      <th>minutes</th>\n",
       "      <th>own_goals</th>\n",
       "      <th>penalties_missed</th>\n",
       "      <th>penalties_saved</th>\n",
       "      <th>red_cards</th>\n",
       "      <th>gw</th>\n",
       "      <th>saves</th>\n",
       "      <th>selected</th>\n",
       "      <th>team_a_score</th>\n",
       "      <th>team_h_score</th>\n",
       "      <th>threat</th>\n",
       "      <th>total_points</th>\n",
       "      <th>transfers_balance</th>\n",
       "      <th>transfers_in</th>\n",
       "      <th>transfers_out</th>\n",
       "      <th>value</th>\n",
       "      <th>was_home</th>\n",
       "      <th>yellow_cards</th>\n",
       "      <th>name</th>\n",
       "      <th>team_name</th>\n",
       "      <th>promoted_side</th>\n",
       "      <th>top_6_last_season</th>\n",
       "      <th>season</th>\n",
       "      <th>position_DEF</th>\n",
       "      <th>position_FWD</th>\n",
       "      <th>position_GK</th>\n",
       "      <th>position_MID</th>\n",
       "      <th>team_name_opponent</th>\n",
       "      <th>promoted_side_opponent</th>\n",
       "      <th>top_6_last_season_opponent</th>\n",
       "      <th>late_kickoff</th>\n",
       "      <th>early_kickoff</th>\n",
       "      <th>kickoff_month_Aug</th>\n",
       "      <th>kickoff_month_Sep</th>\n",
       "      <th>kickoff_month_Oct</th>\n",
       "      <th>kickoff_month_Nov</th>\n",
       "      <th>kickoff_month_Dec</th>\n",
       "      <th>kickoff_month_Jan</th>\n",
       "      <th>kickoff_month_Feb</th>\n",
       "      <th>kickoff_month_Mar</th>\n",
       "      <th>kickoff_month_Apr</th>\n",
       "      <th>kickoff_month_May</th>\n",
       "      <th>season_order</th>\n",
       "      <th>next_match_value</th>\n",
       "      <th>next_match_was_home</th>\n",
       "      <th>next_match_promoted_side_opponent</th>\n",
       "      <th>next_match_top_6_last_season_opponent</th>\n",
       "      <th>next_match_kickoff_month_Aug</th>\n",
       "      <th>next_match_kickoff_month_Sep</th>\n",
       "      <th>next_match_kickoff_month_Oct</th>\n",
       "      <th>next_match_kickoff_month_Nov</th>\n",
       "      <th>next_match_kickoff_month_Dec</th>\n",
       "      <th>next_match_kickoff_month_Jan</th>\n",
       "      <th>next_match_kickoff_month_Feb</th>\n",
       "      <th>next_match_kickoff_month_Mar</th>\n",
       "      <th>next_match_kickoff_month_Apr</th>\n",
       "      <th>next_match_kickoff_month_May</th>\n",
       "      <th>next_match_late_kickoff</th>\n",
       "      <th>next_match_early_kickoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14023</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>aaron_cresswell</td>\n",
       "      <td>West Ham United</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11531</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3002</td>\n",
       "      <td>79</td>\n",
       "      <td>3081</td>\n",
       "      <td>5.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>aaron_cresswell</td>\n",
       "      <td>West Ham United</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9587</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2053</td>\n",
       "      <td>28</td>\n",
       "      <td>2081</td>\n",
       "      <td>5.4</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>aaron_cresswell</td>\n",
       "      <td>West Ham United</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8427</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1221</td>\n",
       "      <td>45</td>\n",
       "      <td>1266</td>\n",
       "      <td>5.4</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>aaron_cresswell</td>\n",
       "      <td>West Ham United</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Watford</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7933</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-520</td>\n",
       "      <td>29</td>\n",
       "      <td>549</td>\n",
       "      <td>5.4</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>aaron_cresswell</td>\n",
       "      <td>West Ham United</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>West Bromwich Albion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   assists  bonus  bps  clean_sheets  creativity  goals_conceded  \\\n",
       "0        0      0    0             0         0.0               0   \n",
       "1        0      0    0             0         0.0               0   \n",
       "2        0      0    0             0         0.0               0   \n",
       "3        0      0    0             0         0.0               0   \n",
       "4        0      0    0             0         0.0               0   \n",
       "\n",
       "   goals_scored  ict_index  influence  minutes  own_goals  penalties_missed  \\\n",
       "0             0        0.0        0.0        0          0                 0   \n",
       "1             0        0.0        0.0        0          0                 0   \n",
       "2             0        0.0        0.0        0          0                 0   \n",
       "3             0        0.0        0.0        0          0                 0   \n",
       "4             0        0.0        0.0        0          0                 0   \n",
       "\n",
       "   penalties_saved  red_cards  gw  saves  selected  team_a_score  \\\n",
       "0                0          0   1      0     14023             1   \n",
       "1                0          0   2      0     11531             0   \n",
       "2                0          0   3      0      9587             1   \n",
       "3                0          0   4      0      8427             4   \n",
       "4                0          0   5      0      7933             2   \n",
       "\n",
       "   team_h_score  threat  total_points  transfers_balance  transfers_in  \\\n",
       "0             2     0.0             0                  0             0   \n",
       "1             1     0.0             0              -3002            79   \n",
       "2             3     0.0             0              -2053            28   \n",
       "3             2     0.0             0              -1221            45   \n",
       "4             4     0.0             0               -520            29   \n",
       "\n",
       "   transfers_out  value  was_home  yellow_cards             name  \\\n",
       "0              0    5.5     False             0  aaron_cresswell   \n",
       "1           3081    5.5      True             0  aaron_cresswell   \n",
       "2           2081    5.4     False             0  aaron_cresswell   \n",
       "3           1266    5.4      True             0  aaron_cresswell   \n",
       "4            549    5.4     False             0  aaron_cresswell   \n",
       "\n",
       "         team_name  promoted_side  top_6_last_season   season  position_DEF  \\\n",
       "0  West Ham United              0                  0  2016-17             1   \n",
       "1  West Ham United              0                  0  2016-17             1   \n",
       "2  West Ham United              0                  0  2016-17             1   \n",
       "3  West Ham United              0                  0  2016-17             1   \n",
       "4  West Ham United              0                  0  2016-17             1   \n",
       "\n",
       "   position_FWD  position_GK  position_MID    team_name_opponent  \\\n",
       "0             0            0             0               Chelsea   \n",
       "1             0            0             0           Bournemouth   \n",
       "2             0            0             0       Manchester City   \n",
       "3             0            0             0               Watford   \n",
       "4             0            0             0  West Bromwich Albion   \n",
       "\n",
       "   promoted_side_opponent  top_6_last_season_opponent  late_kickoff  \\\n",
       "0                       0                           0             1   \n",
       "1                       0                           0             0   \n",
       "2                       0                           1             0   \n",
       "3                       0                           0             0   \n",
       "4                       0                           0             0   \n",
       "\n",
       "   early_kickoff  kickoff_month_Aug  kickoff_month_Sep  kickoff_month_Oct  \\\n",
       "0              0                  1                  0                  0   \n",
       "1              0                  1                  0                  0   \n",
       "2              0                  1                  0                  0   \n",
       "3              0                  0                  1                  0   \n",
       "4              0                  0                  1                  0   \n",
       "\n",
       "   kickoff_month_Nov  kickoff_month_Dec  kickoff_month_Jan  kickoff_month_Feb  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   kickoff_month_Mar  kickoff_month_Apr  kickoff_month_May  season_order  \\\n",
       "0                  0                  0                  0             1   \n",
       "1                  0                  0                  0             1   \n",
       "2                  0                  0                  0             1   \n",
       "3                  0                  0                  0             1   \n",
       "4                  0                  0                  0             1   \n",
       "\n",
       "   next_match_value  next_match_was_home  next_match_promoted_side_opponent  \\\n",
       "0               5.5                  1.0                                0.0   \n",
       "1               5.4                  0.0                                0.0   \n",
       "2               5.4                  1.0                                0.0   \n",
       "3               5.4                  0.0                                0.0   \n",
       "4               5.4                  1.0                                0.0   \n",
       "\n",
       "   next_match_top_6_last_season_opponent  next_match_kickoff_month_Aug  \\\n",
       "0                                    0.0                           1.0   \n",
       "1                                    1.0                           1.0   \n",
       "2                                    0.0                           0.0   \n",
       "3                                    0.0                           0.0   \n",
       "4                                    1.0                           0.0   \n",
       "\n",
       "   next_match_kickoff_month_Sep  next_match_kickoff_month_Oct  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           1.0                           0.0   \n",
       "3                           1.0                           0.0   \n",
       "4                           1.0                           0.0   \n",
       "\n",
       "   next_match_kickoff_month_Nov  next_match_kickoff_month_Dec  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   next_match_kickoff_month_Jan  next_match_kickoff_month_Feb  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   next_match_kickoff_month_Mar  next_match_kickoff_month_Apr  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   next_match_kickoff_month_May  next_match_late_kickoff  \\\n",
       "0                           0.0                      0.0   \n",
       "1                           0.0                      0.0   \n",
       "2                           0.0                      0.0   \n",
       "3                           0.0                      0.0   \n",
       "4                           0.0                      0.0   \n",
       "\n",
       "   next_match_early_kickoff  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(all_data.shape)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2016-17', '2017-18', '2018-19'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['season'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['total_points_plus1_gw'] = all_data.groupby(['name'])['total_points'].shift(-1)\n",
    "all_data = all_data[~all_data['total_points_plus1_gw'].isnull()]  # drop nulls (last gw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/dev/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now added a random_state parameter to `custom_train_test_split` to ensure consistent training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion in test set: 0.09869880673982132\n",
      "Test set size: (6584, 70)\n",
      "Training set size: (60124, 70)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevengeorge/opt/anaconda3/envs/fpl-analysis/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "training_df, test_df = custom_train_test_split(all_data, random_state=RANDOM_SEED, rand_sample_prop=0.0027)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion in test set: 0.10238839731222141\n",
      "Test set size: (6156, 70)\n",
      "Training set size: (53968, 70)\n"
     ]
    }
   ],
   "source": [
    "training_df, dev_df = custom_train_test_split(training_df, random_state=RANDOM_SEED, rand_sample_prop=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion training: 0.8090184085866763\n",
      "Proportion dev: 0.09228278467350243\n",
      "Proportion test: 0.09869880673982132\n"
     ]
    }
   ],
   "source": [
    "print(f\"Proportion training: {training_df.shape[0]/all_data.shape[0]}\")\n",
    "print(f\"Proportion dev: {dev_df.shape[0]/all_data.shape[0]}\")\n",
    "print(f\"Proportion test: {test_df.shape[0]/all_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now get a close 80/10/10 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = _load_model_from_pickle('src/models/pickles/min_max_scalar_lstm_v4.pickle')\n",
    "COLUMNS_TO_SCALE = _load_model_from_pickle('src/models/pickles/min_max_scalar_columns_v4.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out ineligible players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STEPS_IN = 5\n",
    "N_STEPS_OUT = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_eligible_players(training_subset_df):\n",
    "    training_subset_df['total_number_of_gameweeks'] = training_subset_df.groupby(['name']).transform('count')['team_name']\n",
    "    training_subset_df = training_subset_df[training_subset_df['total_number_of_gameweeks'] >= (N_STEPS_IN + N_STEPS_OUT - 1)]\n",
    "    training_subset_df.drop('total_number_of_gameweeks', axis=1, inplace=True)\n",
    "    \n",
    "    return training_subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = filter_eligible_players(training_df)\n",
    "dev_df = filter_eligible_players(dev_df)\n",
    "test_df = filter_eligible_players(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_lstm(df):\n",
    "    df = df.copy()    \n",
    "    df[COLUMNS_TO_SCALE] = mms.transform(df[COLUMNS_TO_SCALE])\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for player in list(df['name'].unique()):\n",
    "        player_df = df[df['name'] == player]\n",
    "        player_df.drop(\n",
    "            COLUMNS_TO_DROP_FOR_TRAINING,\n",
    "            axis=1,\n",
    "            inplace=True\n",
    "        )\n",
    "        X_player, y_player = split_sequences(\n",
    "            df=player_df,\n",
    "            target_column='total_points_plus1_gw',\n",
    "            n_steps_in=N_STEPS_IN,\n",
    "            n_steps_out=N_STEPS_OUT\n",
    "        )\n",
    "        X_list.append(X_player)\n",
    "        y_list.append(y_player)\n",
    "\n",
    "    X = np.concatenate(X_list, axis=0)\n",
    "    y = np.concatenate(y_list, axis=0)\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevengeorge/opt/anaconda3/envs/fpl-analysis/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45691, 5, 63)\n",
      "(45691, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevengeorge/opt/anaconda3/envs/fpl-analysis/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4995, 5, 63)\n",
      "(4995, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevengeorge/opt/anaconda3/envs/fpl-analysis/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5355, 5, 63)\n",
      "(5355, 5)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = prepare_data_for_lstm(training_df)\n",
    "X_dev, y_dev = prepare_data_for_lstm(dev_df)\n",
    "X_test, y_test = prepare_data_for_lstm(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreate best LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.LSTM.bayes_hyperparameter_search import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab_trials_dict = pickle.load(open('src/models/pickles/colab_trials_dict.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bayes_trials', 'best'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colab_trials_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_trials = colab_trials_dict['bayes_trials']\n",
    "best = colab_trials_dict['best']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 527.0,\n",
       " 'dense_dropout': 0.46,\n",
       " 'dense_units': 25.0,\n",
       " 'learning_rate': 0.0010974169408205815,\n",
       " 'lstm_dropout': 0.02,\n",
       " 'lstm_output_dropout': 0.03,\n",
       " 'lstm_recurrent_dropout': 0.5,\n",
       " 'lstm_units': 15.0,\n",
       " 'n_dense_layers': 0.0,\n",
       " 'n_lstm_layers': 1.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = best.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitting_params = {}\n",
    "fitting_params['learning_rate'] = hyperparams['learning_rate']\n",
    "fitting_params['batch_size'] = hyperparams['batch_size']\n",
    "\n",
    "del hyperparams['learning_rate'], hyperparams['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dense_dropout': 0.46,\n",
       " 'dense_units': 25.0,\n",
       " 'lstm_dropout': 0.02,\n",
       " 'lstm_output_dropout': 0.03,\n",
       " 'lstm_recurrent_dropout': 0.5,\n",
       " 'lstm_units': 15.0,\n",
       " 'n_dense_layers': 0.0,\n",
       " 'n_lstm_layers': 1.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0010974169408205815, 'batch_size': 527.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitting_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitting_params['batch_size'] = int(fitting_params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTEGER_PARAMS = ['n_lstm_layers', 'lstm_units', 'n_dense_layers', 'dense_units', 'batch_size']\n",
    "\n",
    "for hyper in INTEGER_PARAMS:\n",
    "    try:\n",
    "        as_int = int(hyperparams[hyper])\n",
    "        hyperparams[hyper] = as_int\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lstm = create_model(n_steps_in=N_STEPS_IN, n_steps_out=N_STEPS_OUT, n_features=63, **hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lstm_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_layer_1 (LSTM)          (None, 15)                4740      \n",
      "_________________________________________________________________\n",
      "lstm_layer_1_dropout (Dropou (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_output (Dense)         (None, 5)                 80        \n",
      "=================================================================\n",
      "Total params: 4,820\n",
      "Trainable params: 4,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = optimizers.Adam(learning_rate=fitting_params['learning_rate'])\n",
    "best_lstm.compile(loss='mse', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45691 samples, validate on 4995 samples\n",
      "Epoch 1/30\n",
      "45691/45691 [==============================] - 2s 40us/step - loss: 6.7736 - val_loss: 7.9369\n",
      "Epoch 2/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 5.4845 - val_loss: 6.8562\n",
      "Epoch 3/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 5.0034 - val_loss: 6.6854\n",
      "Epoch 4/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.9111 - val_loss: 6.6129\n",
      "Epoch 5/30\n",
      "45691/45691 [==============================] - 1s 26us/step - loss: 4.8698 - val_loss: 6.5665\n",
      "Epoch 6/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.8439 - val_loss: 6.5376\n",
      "Epoch 7/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.8269 - val_loss: 6.5173\n",
      "Epoch 8/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.8144 - val_loss: 6.5034\n",
      "Epoch 9/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.8062 - val_loss: 6.4918\n",
      "Epoch 10/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.7949 - val_loss: 6.4855\n",
      "Epoch 11/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.7864 - val_loss: 6.4790\n",
      "Epoch 12/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.7753 - val_loss: 6.4688\n",
      "Epoch 13/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.7687 - val_loss: 6.4659\n",
      "Epoch 14/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.7652 - val_loss: 6.4607\n",
      "Epoch 15/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.7628 - val_loss: 6.4555\n",
      "Epoch 16/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.7524 - val_loss: 6.4523\n",
      "Epoch 17/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.7492 - val_loss: 6.4497\n",
      "Epoch 18/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.7457 - val_loss: 6.4426\n",
      "Epoch 19/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.7410 - val_loss: 6.4472\n",
      "Epoch 20/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.7314 - val_loss: 6.4375\n",
      "Epoch 21/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.7345 - val_loss: 6.4388\n",
      "Epoch 22/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.7275 - val_loss: 6.4469\n",
      "Epoch 23/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.7246 - val_loss: 6.4350\n",
      "Epoch 24/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.7216 - val_loss: 6.4355\n",
      "Epoch 25/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.7206 - val_loss: 6.4381\n",
      "Epoch 26/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.7134 - val_loss: 6.4320\n",
      "Epoch 27/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.7067 - val_loss: 6.4414\n",
      "Epoch 28/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.7089 - val_loss: 6.4337\n",
      "Epoch 29/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.7017 - val_loss: 6.4328\n",
      "Epoch 30/30\n",
      "45691/45691 [==============================] - 1s 25us/step - loss: 4.7032 - val_loss: 6.4493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fd448048cd0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "best_lstm.fit(X_train, y_train, batch_size=fitting_params['batch_size'], epochs=30, validation_data=(X_dev, y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.669168704778555"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, best_lstm.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure why training loss is different to loss at epoch 30?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.449271405480284"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_dev, best_lstm.predict(X_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a classification target\n",
    "\n",
    "Many of the players in our sample are 'bench warmers' i.e. play very few minutes throughout the season. This manifests itself as 0 total points for all future gameweeks in our y sample.\n",
    "\n",
    "Previously our model had to predict points for bench warmers and regular starters at the same time. It is able to get a good MSE by generally making lower points predictions. We also found that minutes and minutes in the previous gameweek are the most important features of the model. This is likely because it is the strongest indicator of whether or not a player is a bench warmer.\n",
    "\n",
    "We can try separating our problem into 2 separate tasks:\n",
    "\n",
    "1. A classification model to see if a player is a bench warmer or not\n",
    "\n",
    "2. A regression model to predict points scored by regular starters\n",
    "\n",
    "The MSE of our regression model should be more meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explore a few different classification targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 in all 5 future GWs\n",
    "bw_zero_all_5_train_mask = ((y_train == 0).sum(axis=1) == 5)\n",
    "\n",
    "# 3 or more 0s in next 5 GWs\n",
    "bw_3_or_more_zeros_train_mask = ((y_train == 0).sum(axis=1) >= 3)\n",
    "\n",
    "# 0 in next GW\n",
    "bw_zero_in_next_gw_train_mask = (y_train[:, 0] == 0)\n",
    "\n",
    "# 0 in next 2 GWs\n",
    "bw_zero_in_next_2_gws_train_mask = ((y_train[:, :2] == 0).sum(axis=1) == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% benchwarmers with classification target '0 in all 5 future GWs': 37%\n",
      "% benchwarmers with classification target '3 or more 0s in next 5 GWs': 54%\n",
      "% benchwarmers with classification target '0 in next GW': 55%\n",
      "% benchwarmers with classification target '0 in next 2 GWs': 47%\n"
     ]
    }
   ],
   "source": [
    "print(f\"% benchwarmers with classification target '0 in all 5 future GWs': {int(bw_zero_all_5_train_mask.mean() * 100)}%\")\n",
    "print(f\"% benchwarmers with classification target '3 or more 0s in next 5 GWs': {int(bw_3_or_more_zeros_train_mask.mean() * 100)}%\")\n",
    "print(f\"% benchwarmers with classification target '0 in next GW': {int(bw_zero_in_next_gw_train_mask.mean() * 100)}%\")\n",
    "print(f\"% benchwarmers with classification target '0 in next 2 GWs': {int(bw_zero_in_next_2_gws_train_mask.mean() * 100)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more benchwarmers the lower the amount of training data for our regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit some out-of-the-box lightgbms to get an idea of which of these targets is easiest to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_benchwarmer_mask(y, mask_type):\n",
    "    if mask_type == 'bw_zero_all_5_train_mask':\n",
    "        return ((y == 0).sum(axis=1) == 5)\n",
    "    elif mask_type == 'bw_3_or_more_zeros_train_mask':\n",
    "        return ((y == 0).sum(axis=1) >= 3)\n",
    "    elif mask_type == 'bw_zero_in_next_gw':\n",
    "        return (y[:, 0] == 0)\n",
    "    elif mask_type == 'bw_zero_in_next_2_gws':\n",
    "        return ((y[:, :2] == 0).sum(axis=1) == 2)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mask_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bw_zero_all_5_train_mask\n",
      "\n",
      "\n",
      "Train ROC AUC: 0.9634287487443152\n",
      "\n",
      "\n",
      "Dev ROC AUC: 0.9380248414644258\n",
      "\n",
      "\n",
      "[[3286  283]\n",
      " [ 315 1111]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      3569\n",
      "           1       0.80      0.78      0.79      1426\n",
      "\n",
      "    accuracy                           0.88      4995\n",
      "   macro avg       0.85      0.85      0.85      4995\n",
      "weighted avg       0.88      0.88      0.88      4995\n",
      "\n",
      "\n",
      "\n",
      "bw_3_or_more_zeros_train_mask\n",
      "\n",
      "\n",
      "Train ROC AUC: 0.9433223396498847\n",
      "\n",
      "\n",
      "Dev ROC AUC: 0.8866478469283379\n",
      "\n",
      "\n",
      "[[2366  366]\n",
      " [ 545 1718]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84      2732\n",
      "           1       0.82      0.76      0.79      2263\n",
      "\n",
      "    accuracy                           0.82      4995\n",
      "   macro avg       0.82      0.81      0.81      4995\n",
      "weighted avg       0.82      0.82      0.82      4995\n",
      "\n",
      "\n",
      "\n",
      "bw_zero_in_next_gw\n",
      "\n",
      "\n",
      "Train ROC AUC: 0.9405273323964082\n",
      "\n",
      "\n",
      "Dev ROC AUC: 0.8909425451435143\n",
      "\n",
      "\n",
      "[[2271  318]\n",
      " [ 556 1850]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84      2589\n",
      "           1       0.85      0.77      0.81      2406\n",
      "\n",
      "    accuracy                           0.83      4995\n",
      "   macro avg       0.83      0.82      0.82      4995\n",
      "weighted avg       0.83      0.83      0.82      4995\n",
      "\n",
      "\n",
      "\n",
      "bw_zero_in_next_2_gws\n",
      "\n",
      "\n",
      "Train ROC AUC: 0.9538932527382747\n",
      "\n",
      "\n",
      "Dev ROC AUC: 0.9183998453780284\n",
      "\n",
      "\n",
      "[[2761  310]\n",
      " [ 405 1519]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89      3071\n",
      "           1       0.83      0.79      0.81      1924\n",
      "\n",
      "    accuracy                           0.86      4995\n",
      "   macro avg       0.85      0.84      0.85      4995\n",
      "weighted avg       0.86      0.86      0.86      4995\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for mask_type in ['bw_zero_all_5_train_mask', 'bw_3_or_more_zeros_train_mask', 'bw_zero_in_next_gw', 'bw_zero_in_next_2_gws']:\n",
    "    \n",
    "    print(mask_type)\n",
    "    print('\\n')\n",
    "    \n",
    "    bw_mask_train = create_benchwarmer_mask(y_train, mask_type)\n",
    "    bw_mask_dev = create_benchwarmer_mask(y_dev, mask_type)\n",
    "    \n",
    "    lgbm = lightgbm.LGBMClassifier()\n",
    "    lgbm.fit(\n",
    "        X_train.reshape(X_train.shape[0], -1),\n",
    "        bw_mask_train.astype(int)\n",
    "    )\n",
    "    \n",
    "    rocauc = roc_auc_score(\n",
    "        bw_mask_train.astype(int),\n",
    "        lgbm.predict_proba(X_train.reshape(X_train.shape[0], -1))[:, 1]\n",
    "    )\n",
    "    \n",
    "    print(f\"Train ROC AUC: {rocauc}\")\n",
    "    print('\\n')\n",
    "    \n",
    "    rocauc = roc_auc_score(\n",
    "        bw_mask_dev.astype(int),\n",
    "        lgbm.predict_proba(X_dev.reshape(X_dev.shape[0], -1))[:, 1]\n",
    "    )\n",
    "    \n",
    "    print(f\"Dev ROC AUC: {rocauc}\")\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\n",
    "        confusion_matrix(\n",
    "            bw_mask_dev.astype(int),\n",
    "            lgbm.predict(X_dev.reshape(X_dev.shape[0], -1))\n",
    "        )\n",
    "    )\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\n",
    "        classification_report(\n",
    "            bw_mask_dev.astype(int),\n",
    "            lgbm.predict(X_dev.reshape(X_dev.shape[0], -1))\n",
    "        )\n",
    "    )\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `0 in all 5 future GWs` as our classification target:\n",
    "\n",
    "- Best dev ROC AUC (93%)    \n",
    "- Lowest overall target rate (37%) --> more examples for regression problem\n",
    "- We can tweak cut-off for desired effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With this classification target use random search to find a better lightgbm model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We may want to use LSTM instead but lets continue to use lightgbm for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM_DISTRIBUTIONS = {\n",
    "    'num_leaves': list(range(20, 150)),\n",
    "    'learning_rate': list(np.logspace(np.log10(0.005), np.log10(0.5), base=10, num=1000)),\n",
    "    'subsample_for_bin': list(range(20000, 300000, 20000)),\n",
    "    'min_child_samples': list(range(20, 500, 5)),\n",
    "    'reg_alpha': list(np.logspace(np.log10(0.01), np.log10(100), base=10, num=1000)),\n",
    "    'reg_lambda': list(np.logspace(np.log10(0.01), np.log10(100), base=10, num=1000)),\n",
    "    'colsample_bytree': list(np.linspace(0.6, 1, 10)),\n",
    "    'subsample': list(np.linspace(0.5, 1, 100)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_class = RandomizedSearchCV(\n",
    "    lightgbm.LGBMClassifier(),\n",
    "    param_distributions=PARAM_DISTRIBUTIONS,\n",
    "    n_iter=25,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_mask_train = create_benchwarmer_mask(y_train, 'bw_zero_all_5_train_mask')\n",
    "bw_mask_dev = create_benchwarmer_mask(y_dev, 'bw_zero_all_5_train_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   52.7s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=LGBMClassifier(boosting_type='gbdt',\n",
       "                                            class_weight=None,\n",
       "                                            colsample_bytree=1.0,\n",
       "                                            importance_type='split',\n",
       "                                            learning_rate=0.1, max_depth=-1,\n",
       "                                            min_child_samples=20,\n",
       "                                            min_child_weight=0.001,\n",
       "                                            min_split_gain=0.0,\n",
       "                                            n_estimators=100, n_jobs=-1,\n",
       "                                            num_leaves=31, objective=None,\n",
       "                                            random_state=None, reg_alpha=0.0,\n",
       "                                            reg_lambda=0.0, sile...\n",
       "                                                      0.6161616161616161,\n",
       "                                                      0.6212121212121212,\n",
       "                                                      0.6262626262626263,\n",
       "                                                      0.6313131313131313,\n",
       "                                                      0.6363636363636364,\n",
       "                                                      0.6414141414141414,\n",
       "                                                      0.6464646464646464, ...],\n",
       "                                        'subsample_for_bin': [20000, 40000,\n",
       "                                                              60000, 80000,\n",
       "                                                              100000, 120000,\n",
       "                                                              140000, 160000,\n",
       "                                                              180000, 200000,\n",
       "                                                              220000, 240000,\n",
       "                                                              260000, 280000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_class.fit(\n",
    "    X_train.reshape(X_train.shape[0], -1),\n",
    "    bw_mask_train.astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC: 0.9523711434818718\n",
      "\n",
      "\n",
      "Dev ROC AUC: 0.939351718495365\n",
      "\n",
      "\n",
      "[[3305  264]\n",
      " [ 330 1096]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      3569\n",
      "           1       0.81      0.77      0.79      1426\n",
      "\n",
      "    accuracy                           0.88      4995\n",
      "   macro avg       0.86      0.85      0.85      4995\n",
      "weighted avg       0.88      0.88      0.88      4995\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rocauc = roc_auc_score(\n",
    "    bw_mask_train.astype(int),\n",
    "    lgbm_class.predict_proba(X_train.reshape(X_train.shape[0], -1))[:, 1]\n",
    ")\n",
    "\n",
    "print(f\"Train ROC AUC: {rocauc}\")\n",
    "print('\\n')\n",
    "\n",
    "rocauc = roc_auc_score(\n",
    "    bw_mask_dev.astype(int),\n",
    "    lgbm_class.predict_proba(X_dev.reshape(X_dev.shape[0], -1))[:, 1]\n",
    ")\n",
    "\n",
    "print(f\"Dev ROC AUC: {rocauc}\")\n",
    "print('\\n')\n",
    "\n",
    "print(\n",
    "    confusion_matrix(\n",
    "        bw_mask_dev.astype(int),\n",
    "        lgbm_class.predict(X_dev.reshape(X_dev.shape[0], -1))\n",
    "    )\n",
    ")\n",
    "print('\\n')\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        bw_mask_dev.astype(int),\n",
    "        lgbm_class.predict(X_dev.reshape(X_dev.shape[0], -1))\n",
    "    )\n",
    ")\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given our classification target, how does our best LSTM perform on each task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fd44cba0090>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.449271405480284"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_dev, best_lstm.predict(X_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.669168704778555"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, best_lstm.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bench warmers MSE (Dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5117241488969464"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_dev[bw_mask_dev], best_lstm.predict(X_dev[bw_mask_dev]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular starters MSE (Dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.821628475477073"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_dev[~bw_mask_dev], best_lstm.predict(X_dev[~bw_mask_dev]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bench warmers MSE (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3320833681470786"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train[bw_mask_train], best_lstm.predict(X_train[bw_mask_train]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular starters MSE (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.267989220203094"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train[~bw_mask_train], best_lstm.predict(X_train[~bw_mask_train]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our MSE is worse for our regular starters compared to the overall MSE. Lets build a new LSTM with the objective of predicting points scored by regular starters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_What is our overall MSE if we use the best LSTM in a two step fashion?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_benchwarmer = lgbm_class.predict(X_dev.reshape(X_dev.shape[0], -1)).astype(bool)\n",
    "is_benchwarmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_dev_predictions = best_lstm.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_dev_predictions[is_benchwarmer, :] = 0  # Set all 5 GWs to 0 for players predicted as bench warmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.467370809515126"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_dev, lstm_dev_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dev MSE only marginally higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False,  True, False])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_benchwarmer = lgbm_class.predict(X_train.reshape(X_train.shape[0], -1)).astype(bool)\n",
    "is_benchwarmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_train_predictions = best_lstm.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_train_predictions[is_benchwarmer, :] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.670570694341639"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, lstm_train_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our 2 step approach hasn't made MSE error much worse. Hopefully more focussed models on each task can lead to an overall improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM regular starters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our training set will use the ground truth classification labels rather than the predictions of the lightgbm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45691, 5, 63)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_reg_start = Sequential(name='LSTM regular starters')\n",
    "lstm_reg_start.add(\n",
    "    LSTM(\n",
    "        units=15,\n",
    "        dropout=0.0004,\n",
    "        recurrent_dropout=0.0004,\n",
    "        input_shape=(5, 63),\n",
    "        name='lstm_layer_1'\n",
    "    )\n",
    ")\n",
    "lstm_reg_start.add(\n",
    "    Dropout(\n",
    "        rate=0.001,\n",
    "        name='lstm_layer_1_dropout'\n",
    "    )\n",
    ")\n",
    "\n",
    "# lstm_reg_start.add(Dense(20, name=f'dense_layer_1'))\n",
    "# lstm_reg_start.add(BatchNormalization(name=f'dense_batch_norm_1'))\n",
    "# lstm_reg_start.add(Activation('relu', name=f'dense_activation_1'))\n",
    "# lstm_reg_start.add(Dropout(rate=0.001, name=f'dense_dropout_1'))\n",
    "\n",
    "lstm_reg_start.add(\n",
    "    Dense(\n",
    "        5, kernel_initializer=initializers.glorot_normal(), name='dense_output'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM regular starters\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_layer_1 (LSTM)          (None, 15)                4740      \n",
      "_________________________________________________________________\n",
      "lstm_layer_1_dropout (Dropou (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_output (Dense)         (None, 5)                 80        \n",
      "=================================================================\n",
      "Total params: 4,820\n",
      "Trainable params: 4,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_reg_start.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "lstm_reg_start.compile(loss='mean_squared_error', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28571 samples, validate on 3569 samples\n",
      "Epoch 1/20\n",
      "28571/28571 [==============================] - 2s 55us/step - loss: 8.7217 - val_loss: 9.2545\n",
      "Epoch 2/20\n",
      "28571/28571 [==============================] - 1s 38us/step - loss: 7.4353 - val_loss: 8.8396\n",
      "Epoch 3/20\n",
      "28571/28571 [==============================] - 1s 38us/step - loss: 7.2945 - val_loss: 8.7434\n",
      "Epoch 4/20\n",
      "28571/28571 [==============================] - 1s 38us/step - loss: 7.2453 - val_loss: 8.7119\n",
      "Epoch 5/20\n",
      "28571/28571 [==============================] - 1s 38us/step - loss: 7.2245 - val_loss: 8.6949\n",
      "Epoch 6/20\n",
      "28571/28571 [==============================] - 1s 39us/step - loss: 7.2027 - val_loss: 8.7165\n",
      "Epoch 7/20\n",
      "28571/28571 [==============================] - 1s 39us/step - loss: 7.1876 - val_loss: 8.6871\n",
      "Epoch 8/20\n",
      "28571/28571 [==============================] - 1s 38us/step - loss: 7.1735 - val_loss: 8.6751\n",
      "Epoch 9/20\n",
      "28571/28571 [==============================] - 1s 38us/step - loss: 7.1604 - val_loss: 8.6598\n",
      "Epoch 10/20\n",
      "28571/28571 [==============================] - 1s 38us/step - loss: 7.1466 - val_loss: 8.6814\n",
      "Epoch 11/20\n",
      "28571/28571 [==============================] - 1s 38us/step - loss: 7.1344 - val_loss: 8.6982\n",
      "Epoch 12/20\n",
      "28571/28571 [==============================] - 1s 38us/step - loss: 7.1231 - val_loss: 8.6713\n",
      "Epoch 13/20\n",
      "28571/28571 [==============================] - 1s 40us/step - loss: 7.1108 - val_loss: 8.6974\n",
      "Epoch 14/20\n",
      "28571/28571 [==============================] - 1s 38us/step - loss: 7.0975 - val_loss: 8.6786\n",
      "Epoch 15/20\n",
      "28571/28571 [==============================] - 1s 38us/step - loss: 7.0889 - val_loss: 8.7161\n",
      "Epoch 16/20\n",
      "28571/28571 [==============================] - 1s 38us/step - loss: 7.0779 - val_loss: 8.6883\n",
      "Epoch 17/20\n",
      "28571/28571 [==============================] - 1s 38us/step - loss: 7.0657 - val_loss: 8.7328\n",
      "Epoch 18/20\n",
      "28571/28571 [==============================] - 1s 40us/step - loss: 7.0546 - val_loss: 8.6948\n",
      "Epoch 19/20\n",
      "28571/28571 [==============================] - 1s 42us/step - loss: 7.0459 - val_loss: 8.7333\n",
      "Epoch 20/20\n",
      "28571/28571 [==============================] - 1s 39us/step - loss: 7.0361 - val_loss: 8.7246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fd3d69b7550>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_reg_start.fit(\n",
    "    X_train[~bw_mask_train],\n",
    "    y_train[~bw_mask_train],\n",
    "    batch_size=128,\n",
    "    epochs=20,\n",
    "    validation_data=(\n",
    "        X_dev[~bw_mask_dev],\n",
    "        y_dev[~bw_mask_dev]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd3d69b1190>"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(lstm_reg_start.history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.015099859680466"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train[~bw_mask_train], lstm_reg_start.predict(X_train[~bw_mask_train]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some explanations of why training loss different during fit and afterwards:\n",
    "\n",
    "https://github.com/keras-team/keras/issues/6977\n",
    "\n",
    "https://keras.io/getting_started/faq/#why-is-my-training-loss-much-higher-than-my-testing-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.724608248841363"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_dev[~bw_mask_dev], lstm_reg_start.predict(X_dev[~bw_mask_dev]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our error for regular starters with the old LSTM was `8.821628475477073`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_benchwarmer = lgbm_class.predict(X_dev.reshape(X_dev.shape[0], -1)).astype(bool)\n",
    "is_benchwarmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_dev_predictions = lstm_reg_start.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_dev_predictions[is_benchwarmer, :] = 0  # Set all 5 GWs to 0 for players predicted as bench warmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.502808812407702"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_dev, lstm_dev_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old LSTM model: 6.467370809515126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False,  True, False])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_benchwarmer = lgbm_class.predict(X_train.reshape(X_train.shape[0], -1)).astype(bool)\n",
    "is_benchwarmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_train_predictions = lstm_reg_start.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_train_predictions[is_benchwarmer, :] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.606776905782736"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, lstm_train_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old LSTM model: 4.670570694341639"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:\n",
    "\n",
    "- The regular starter LSTM did better than our old LSTM on the ground truth regular starter dev set\n",
    "- However the regular starter LSTM did worse on the _predicted_ LSTM regular starters dev set\n",
    "- The predicted set will contain false positives (players who are bench warmers but the model thinks they are regulars). For these players the MSE will be high because the LSTM has not seen this type of player in training.\n",
    "- Can adjust the cut-off the mitigate this scenario\n",
    "- Nevertheless this 2-step approach seems like a sensible route forward\n",
    "- Also, Fantasy Football Scout only has data for players with > 0 minutes, which makes it ideal for the second model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
